{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DATASET"
      ],
      "metadata": {
        "id": "Mhx8h04WZYnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl_j7EruXk7M",
        "outputId": "2f559512-bce8-4a89-e5a6-e9c2b020c734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Summary:\n",
            "--------------------------------------------------\n",
            "Total number of customers: 1000\n",
            "Churn rate: 26.4%\n",
            "\n",
            "Feature Statistics:\n",
            "--------------------------------------------------\n",
            "       customer_id  months_as_customer  total_purchases  avg_order_value  \\\n",
            "count      1000.00             1000.00          1000.00           941.00   \n",
            "mean       1500.50               30.58            50.89           149.85   \n",
            "std         288.82               17.02            44.53            48.78   \n",
            "min        1001.00                1.00             0.00             5.59   \n",
            "25%        1250.75               16.00            14.00           116.53   \n",
            "50%        1500.50               31.00            39.00           150.46   \n",
            "75%        1750.25               45.00            78.00           182.10   \n",
            "max        2000.00               59.00           182.00           298.25   \n",
            "\n",
            "       support_tickets  last_interaction_days    churn  \n",
            "count          1000.00                1000.00  1000.00  \n",
            "mean              2.01                 177.52     0.26  \n",
            "std               1.38                 105.43     0.44  \n",
            "min               0.00                   1.00     0.00  \n",
            "25%               1.00                  85.00     0.00  \n",
            "50%               2.00                 176.00     0.00  \n",
            "75%               3.00                 271.00     1.00  \n",
            "max               7.00                 364.00     1.00  \n",
            "\n",
            "First few rows of the dataset:\n",
            "--------------------------------------------------\n",
            "   customer_id  months_as_customer  total_purchases  avg_order_value  \\\n",
            "0         1001                  39               29           168.36   \n",
            "1         1002                  52              136           123.71   \n",
            "2         1003                  29               82           143.45   \n",
            "3         1004                  15                7            48.24   \n",
            "4         1005                  43               94           186.61   \n",
            "\n",
            "   support_tickets  last_interaction_days  churn  \n",
            "0                1                    108      0  \n",
            "1                2                    296      0  \n",
            "2                5                    324      1  \n",
            "3                1                    302      1  \n",
            "4                2                    334      1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of customers to generate\n",
        "n_customers = 1000\n",
        "\n",
        "# Generate customer IDs\n",
        "customer_ids = range(1001, 1001 + n_customers)\n",
        "\n",
        "# Generate realistic customer data\n",
        "def generate_customer_data():\n",
        "    data = {\n",
        "        'customer_id': customer_ids,\n",
        "        'months_as_customer': np.random.randint(1, 60, n_customers),\n",
        "        'total_purchases': np.random.randint(1, 100, n_customers),\n",
        "        'avg_order_value': np.random.normal(150, 50, n_customers).round(2),\n",
        "        'support_tickets': np.random.poisson(2, n_customers),\n",
        "        'last_interaction_days': np.random.randint(1, 365, n_customers)\n",
        "    }\n",
        "\n",
        "    # Create correlations to make the data more realistic\n",
        "    # Customers with higher months_as_customer tend to have more total_purchases\n",
        "    data['total_purchases'] = (data['total_purchases'] * (data['months_as_customer'] / 30)).astype(int)\n",
        "\n",
        "    # Calculate churn probability based on features\n",
        "    churn_prob = (\n",
        "        -0.1 * np.log(data['months_as_customer']) +  # Longer-term customers are less likely to churn\n",
        "        0.03 * data['last_interaction_days'] +        # More recent interaction means less likely to churn\n",
        "        -0.02 * data['total_purchases'] +             # More purchases means less likely to churn\n",
        "        0.01 * (data['support_tickets'] ** 2) +       # More support tickets means more likely to churn\n",
        "        np.random.normal(0, 0.1, n_customers)         # Add some randomness\n",
        "    )\n",
        "\n",
        "    # Normalize probabilities\n",
        "    churn_prob = (churn_prob - churn_prob.min()) / (churn_prob.max() - churn_prob.min())\n",
        "\n",
        "    # Convert to binary churn indicator\n",
        "    data['churn'] = (churn_prob > 0.7).astype(int)\n",
        "\n",
        "    # Clean up the data\n",
        "    # Ensure avg_order_value is positive\n",
        "    data['avg_order_value'] = np.abs(data['avg_order_value'])\n",
        "\n",
        "    # Round average order values to 2 decimal places\n",
        "    data['avg_order_value'] = data['avg_order_value'].round(2)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Add some missing values to make it more realistic\n",
        "    mask = np.random.random(n_customers) < 0.05\n",
        "    df.loc[mask, 'avg_order_value'] = np.nan\n",
        "\n",
        "    return df\n",
        "\n",
        "# Generate the dataset\n",
        "df = generate_customer_data()\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('customer_churn_data.csv', index=False)\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\nDataset Summary:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Total number of customers: {len(df)}\")\n",
        "print(f\"Churn rate: {(df['churn'].mean() * 100).round(2)}%\")\n",
        "print(\"\\nFeature Statistics:\")\n",
        "print(\"-\" * 50)\n",
        "print(df.describe().round(2))\n",
        "\n",
        "# Print first few rows\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(\"-\" * 50)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATA ANALYSIS AND PREPROCESSING\n",
        "Load and Explore Data:\n",
        "\n",
        "Read the customer_churn_data.csv file and explore it for insights like missing values, outliers, and distributions of features.\n",
        "\n",
        "Handle Missing Values:\n",
        "\n",
        "Decide on an imputation strategy for missing values in avg_order_value (e.g., mean/median imputation or model-based imputation).\n",
        "\n",
        "Feature Engineering:\n",
        "\n",
        "Scale numerical features or encode categorical ones."
      ],
      "metadata": {
        "id": "VWK8JdIDZeao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def load_and_explore_data(file_path):\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"Dataset loaded successfully.\\n\")\n",
        "    print(\"Initial dataset overview:\\n\", df.head())\n",
        "    print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "    print(\"\\nStatistical Summary:\\n\", df.describe())\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    # Handle missing values\n",
        "    df['avg_order_value'] = df['avg_order_value'].fillna(df['avg_order_value'].median())\n",
        "\n",
        "\n",
        "    # Feature-target split\n",
        "    X = df.drop(columns=['customer_id', 'churn'])\n",
        "    y = df['churn']\n",
        "\n",
        "    # Standardize numerical features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y\n"
      ],
      "metadata": {
        "id": "0r4gYL2YYYcF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL\n",
        "Model Selection:\n",
        "\n",
        "Choose a classification model like Random Forest, Logistic Regression, or Gradient Boosting based on interpretability and performance.\n",
        "\n",
        "Evaluation Metrics:\n",
        "\n",
        "Use metrics like ROC-AUC, confusion matrix etc to evaluate the model."
      ],
      "metadata": {
        "id": "1tGAwJPzZ_Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "def build_model(X_train, X_test, y_train, y_test):\n",
        "    # Initialize and train the model\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    print(\"\\nModel Performance:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(f\"ROC-AUC: {auc:.2f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "V9KSiAqzYZfg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BUSINESS INSIGHTS\n",
        "Feature Importance:\n",
        "\n",
        "Use feature importance metrics to identify key drivers of churn.\n",
        "\n",
        "Insights and Recommendations:\n",
        "\n",
        "Identify customers at high risk of churn.\n"
      ],
      "metadata": {
        "id": "SbcXtQwlabU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_insights(model, df, features):\n",
        "    # Feature importance analysis\n",
        "    importance = model.feature_importances_\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': features,\n",
        "        'Importance': importance\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nFeature Importance:\\n\", feature_importance)\n",
        "\n",
        "    # Business insights\n",
        "    insights = {\n",
        "        \"Key Factors\": feature_importance['Feature'].head(5).tolist(),\n",
        "        \"Recommendations\": [\n",
        "            \"Engage high-risk customers with personalized offers.\",\n",
        "            \"Improve response time for support tickets.\",\n",
        "            \"Target frequent customers for loyalty programs.\"\n",
        "        ]\n",
        "    }\n",
        "    return insights\n"
      ],
      "metadata": {
        "id": "ngpZnNIPYdDK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FLOW BEFORE CROSS VALIDATION"
      ],
      "metadata": {
        "id": "Nw0NnXfPaoTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and explore the data\n",
        "file_path = 'customer_churn_data.csv'\n",
        "df = load_and_explore_data(file_path)\n",
        "\n",
        "# Step 2: Preprocess data\n",
        "X, y = preprocess_data(df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Build and evaluate the model\n",
        "model = build_model(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Step 4: Generate business insights\n",
        "features = df.drop(columns=['customer_id', 'churn']).columns\n",
        "insights = generate_insights(model, df, features)\n",
        "\n",
        "print(\"\\nBusiness Insights:\\n\", insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FPPyjbvYgSX",
        "outputId": "52367510-7697-43ba-85fe-a4692fc97960"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Initial dataset overview:\n",
            "    customer_id  months_as_customer  total_purchases  avg_order_value  \\\n",
            "0         1001                  39               29           168.36   \n",
            "1         1002                  52              136           123.71   \n",
            "2         1003                  29               82           143.45   \n",
            "3         1004                  15                7            48.24   \n",
            "4         1005                  43               94           186.61   \n",
            "\n",
            "   support_tickets  last_interaction_days  churn  \n",
            "0                1                    108      0  \n",
            "1                2                    296      0  \n",
            "2                5                    324      1  \n",
            "3                1                    302      1  \n",
            "4                2                    334      1  \n",
            "\n",
            "Missing values:\n",
            " customer_id               0\n",
            "months_as_customer        0\n",
            "total_purchases           0\n",
            "avg_order_value          59\n",
            "support_tickets           0\n",
            "last_interaction_days     0\n",
            "churn                     0\n",
            "dtype: int64\n",
            "\n",
            "Statistical Summary:\n",
            "        customer_id  months_as_customer  total_purchases  avg_order_value  \\\n",
            "count  1000.000000         1000.000000      1000.000000       941.000000   \n",
            "mean   1500.500000           30.582000        50.886000       149.851169   \n",
            "std     288.819436           17.024838        44.530573        48.775279   \n",
            "min    1001.000000            1.000000         0.000000         5.590000   \n",
            "25%    1250.750000           16.000000        14.000000       116.530000   \n",
            "50%    1500.500000           31.000000        39.000000       150.460000   \n",
            "75%    1750.250000           45.000000        78.000000       182.100000   \n",
            "max    2000.000000           59.000000       182.000000       298.250000   \n",
            "\n",
            "       support_tickets  last_interaction_days       churn  \n",
            "count      1000.000000            1000.000000  1000.00000  \n",
            "mean          2.010000             177.520000     0.26400  \n",
            "std           1.381959             105.434283     0.44102  \n",
            "min           0.000000               1.000000     0.00000  \n",
            "25%           1.000000              85.000000     0.00000  \n",
            "50%           2.000000             176.000000     0.00000  \n",
            "75%           3.000000             271.000000     1.00000  \n",
            "max           7.000000             364.000000     1.00000  \n",
            "\n",
            "Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       139\n",
            "           1       1.00      0.98      0.99        61\n",
            "\n",
            "    accuracy                           0.99       200\n",
            "   macro avg       1.00      0.99      0.99       200\n",
            "weighted avg       1.00      0.99      0.99       200\n",
            "\n",
            "Confusion Matrix:\n",
            " [[139   0]\n",
            " [  1  60]]\n",
            "ROC-AUC: 1.00\n",
            "\n",
            "Feature Importance:\n",
            "                  Feature  Importance\n",
            "4  last_interaction_days    0.823351\n",
            "1        total_purchases    0.096810\n",
            "0     months_as_customer    0.039839\n",
            "2        avg_order_value    0.026950\n",
            "3        support_tickets    0.013049\n",
            "\n",
            "Business Insights:\n",
            " {'Key Factors': ['last_interaction_days', 'total_purchases', 'months_as_customer', 'avg_order_value', 'support_tickets'], 'Recommendations': ['Engage high-risk customers with personalized offers.', 'Improve response time for support tickets.', 'Target frequent customers for loyalty programs.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##K-FOLD CROSS VALIDATION"
      ],
      "metadata": {
        "id": "1NvannfdarEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def perform_cross_validation(X, y, model, cv=5):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross-validation.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Features\n",
        "    - y: Target labels\n",
        "    - model: Machine learning model\n",
        "    - cv: Number of folds (default: 5)\n",
        "\n",
        "    Returns:\n",
        "    - mean_score: Average ROC-AUC score across folds\n",
        "    - all_scores: List of individual fold scores\n",
        "    \"\"\"\n",
        "    # Perform cross-validation\n",
        "    all_scores = cross_val_score(\n",
        "        model, X, y, cv=cv, scoring='roc_auc', n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Cross-Validation Scores (ROC-AUC): {all_scores}\")\n",
        "    print(f\"Mean ROC-AUC Score: {np.mean(all_scores):.4f}\")\n",
        "    return np.mean(all_scores), all_scores\n"
      ],
      "metadata": {
        "id": "R2C5VUoua2-z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FLOW AFTER CROSS VALIDATION"
      ],
      "metadata": {
        "id": "KrXvbWgTbsGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "file_path = 'customer_churn_data.csv'\n",
        "df = load_and_explore_data(file_path)\n",
        "X, y = preprocess_data(df)\n",
        "\n",
        "# Initialize the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "print(\"\\nPerforming K-Fold Cross-Validation...\")\n",
        "mean_score, all_scores = perform_cross_validation(X, y, model, cv=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx9izN0Ea4Jl",
        "outputId": "a69c0a4a-4a48-409f-ff93-44fcf49276c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Initial dataset overview:\n",
            "    customer_id  months_as_customer  total_purchases  avg_order_value  \\\n",
            "0         1001                  39               29           168.36   \n",
            "1         1002                  52              136           123.71   \n",
            "2         1003                  29               82           143.45   \n",
            "3         1004                  15                7            48.24   \n",
            "4         1005                  43               94           186.61   \n",
            "\n",
            "   support_tickets  last_interaction_days  churn  \n",
            "0                1                    108      0  \n",
            "1                2                    296      0  \n",
            "2                5                    324      1  \n",
            "3                1                    302      1  \n",
            "4                2                    334      1  \n",
            "\n",
            "Missing values:\n",
            " customer_id               0\n",
            "months_as_customer        0\n",
            "total_purchases           0\n",
            "avg_order_value          59\n",
            "support_tickets           0\n",
            "last_interaction_days     0\n",
            "churn                     0\n",
            "dtype: int64\n",
            "\n",
            "Statistical Summary:\n",
            "        customer_id  months_as_customer  total_purchases  avg_order_value  \\\n",
            "count  1000.000000         1000.000000      1000.000000       941.000000   \n",
            "mean   1500.500000           30.582000        50.886000       149.851169   \n",
            "std     288.819436           17.024838        44.530573        48.775279   \n",
            "min    1001.000000            1.000000         0.000000         5.590000   \n",
            "25%    1250.750000           16.000000        14.000000       116.530000   \n",
            "50%    1500.500000           31.000000        39.000000       150.460000   \n",
            "75%    1750.250000           45.000000        78.000000       182.100000   \n",
            "max    2000.000000           59.000000       182.000000       298.250000   \n",
            "\n",
            "       support_tickets  last_interaction_days       churn  \n",
            "count      1000.000000            1000.000000  1000.00000  \n",
            "mean          2.010000             177.520000     0.26400  \n",
            "std           1.381959             105.434283     0.44102  \n",
            "min           0.000000               1.000000     0.00000  \n",
            "25%           1.000000              85.000000     0.00000  \n",
            "50%           2.000000             176.000000     0.00000  \n",
            "75%           3.000000             271.000000     1.00000  \n",
            "max           7.000000             364.000000     1.00000  \n",
            "\n",
            "Performing K-Fold Cross-Validation...\n",
            "Cross-Validation Scores (ROC-AUC): [0.9970764  0.99858811 0.9980747  0.99987165 0.99582852]\n",
            "Mean ROC-AUC Score: 0.9979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Git (first time setup)\n",
        "!git config --global user.name \"lolipie007\"\n",
        "!git config --global user.email \"pratik.kartik2003@gmail.com\"\n",
        "\n"
      ],
      "metadata": {
        "id": "PltBZwI-dXOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}